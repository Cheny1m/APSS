    def get_costs(ori_dataset, cost_c_dataset, dataset, pi):
        node_size = dataset.shape[1] + 1  # 这里输入的node数量是nodesize-1数量
        # costs = []
        # for idx in range(pi.shape[0]):
        #     position = pi[idx, :]
        #     position = position.asnumpy().tolist()
        #     data = ori_dataset[idx, :, 0]
        #     cost_data = cost_c_dataset[idx, ...]
        #     partition = pi2partition(position, node_size) 
        #     costs.append(get_partition_cost_sequence(data, cost_data, partition))

        # 不要用循环，而是用矩阵操作
        # print("pi.shape[0]:",pi.shape[0],pi.shape,pi)
        # print("ori_dataset",ori_dataset.shape)
        # print("cost_c_dataset",cost_c_dataset.shape)
        # print("dataset",dataset.shape)
        pi,_ = ops.sort(pi,-1)
        # print("pi.shape[0]:",pi.shape,pi)
        
        # pi节点 parti添加分区 但pi可以当节点来使用segement算子进行求和(暂不清楚效率)
        # pi.shape[b,3],parti.shape[b,4]
        # pi = [0,1,2] parti = [1,1,1,27] p = [0,1,2,29] 

        # partition = ops.cast(partition,ms.int32)
        # p = ops.cumsum(partition,-1) - 1

        node_size_tensor = ops.full((pi.shape[0],1),node_size-1)
        p = ops.concat((pi,node_size_tensor),-1)
        # print("p:",p.shape,p)
        data = ops.cumsum(ori_dataset.squeeze(-1),-1)
        # print("data:",data.shape,data)
        index_data = ops.gather(data,p,1,1)
        # print("index_data",index_data,index_data.shape)
        # 加0作差
        index_data = ops.concat((ops.zeros((index_data.shape[0],1)),index_data),-1)
        max_sub_seq_cost,_  = ops.max(ops.diff(index_data),-1)
        # print("max_sub_seq_cost",max_sub_seq_cost,max_sub_seq_cost.shape)

        # numb = ops.arange(0,pi.shape[-1])
        # indices = ops.stack((ops.arange(1024),p[:,j]),axis=1)

        indices = ops.tile(ops.arange(pi.shape[-1]),(cost_c_dataset.shape[0],1))
        # print("indices",indices,indices.shape)

        # batch_indices = ops.tile(ops.arange(cost_c_dataset.shape[0]).reshape(-1,1),(1,3))
        # print("batch_indices",batch_indices,batch_indices.shape)
        # extended_indices = ops.stack((batch_indices,pi),-1)

        # extended_indices = ops.stack((pi,indices),-1)
        # print("extended_indices",extended_indices,extended_indices.shape)

        cost_data = cost_c_dataset.reshape(cost_c_dataset.shape[0],cost_c_dataset.shape[1]*cost_c_dataset.shape[2])
        # print("cost_data",cost_data,cost_data.shape)
        indices1 = pi*pi.shape[-1] + indices
        # print("indices1",indices1,indices1.shape)
        cost_cost = ops.sum(ops.gather_elements(cost_data, 1,indices1),-1)

        # gather_elements1 = ops.gather_nd(cost_c_dataset,extended_indices)
        # print("gather_elements1",gather_elements1,gather_elements1.shape)
        # cost_cost = ops.sum(gather_elements1,1)
        # print("cost_cost",cost_cost,cost_cost.shape)
        # 已验证实现
        # for j in range(pi.shape[-1]):
        #     indices = ops.stack((ops.arange(cost_c_dataset.shape[0]),p[:,j]),axis=1)
        #     print("indices",indices,indices.shape)

        #     elements = ops.gather_nd(cost_c_dataset[:,:,j],indices)
        #     print("elements",elements,elements.shape)

        #     max_sub_seq_cost += elements
        #     print("max_sub_seq_cost1",max_sub_seq_cost,max_sub_seq_cost.shape)

        
        # indices = ops.arange(0,pi.shape[-1])
        # index_cost = ops.gather(cost_c_dataset,)
        # cost_cost = ops.sum(cost_c_dataset[:,p[:-1],indices])
        # print("cost_cost",cost_cost,cost_cost.shape)
        # max_sub_seq_cost += cost_cost

        max_sub_seq_cost += cost_cost
        # print("max_sub_seq_cost2",max_sub_seq_cost,max_sub_seq_cost.shape)
        return max_sub_seq_cost,None
