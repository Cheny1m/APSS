{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# pip install tqdm\n",
    "# from test import get_partiton_cost_sequence, pipe_ast,pi2partition\n",
    "import numpy as np\n",
    "from nets.attention_model import set_decode_type\n",
    "import time\n",
    "import json\n",
    "import pprint as pp\n",
    "\n",
    "# import torch.multiprocessing as mp\n",
    "import multiprocessing as mp\n",
    "import mindspore\n",
    "import mindspore.nn.optim as optim\n",
    "# pip install tensorboard_logger\n",
    "from tensorboard_logger import Logger as TbLogger\n",
    "\n",
    "from nets.critic_network import CriticNetwork\n",
    "from options import get_options\n",
    "from train import train_epoch, validate, get_inner_model\n",
    "from reinforce_baselines_pp import  RolloutBaselinePP,WarmupBaseline\n",
    "from reinforce_baselines import NoBaseline, ExponentialBaseline, CriticBaseline, RolloutBaseline#, WarmupBaseline\n",
    "from nets.attention_model import AttentionModel\n",
    "from nets.pointer_network import PointerNetwork, CriticNetworkLSTM\n",
    "from utils import load_problem, load_model, load_model_temp#,torch_load_cpu\n",
    "from test import test\n",
    "import math\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import shutil\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import mindspore.nn as nn\n",
    "import sys\n",
    "# sys.path.append(\"/home/oj/distributed_floder/research/AMP/src/\")\n",
    "sys.path.append(\"/root/cym/AMP/src/\")\n",
    "\n",
    "# pip install numpy\n",
    "from sa import amp_no_placement_strategy\n",
    "# pip install spur\n",
    "from cost_het_cluster import  get_cost_e,dp_cost,get_cost_c\n",
    "from amp_utils import simulate, to_float_torch\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import json\n",
    "import copy\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# from amp_utils import rank2axis, axis2rank, get_host\n",
    "from pipe import pipe_ds, pipe_ast, pipe_cost, pipe_uniform, pipe_gpt2\n",
    "import mindspore.numpy as mnp\n",
    "import mindspore.ops as ops\n",
    "import mindspore.context as context\n",
    "# from utils import torch_load_cpu, load_problem\n",
    "# from utils1 import torch_load_cpu, load_problem\n",
    "from utils import mindspore_load_cpu, load_problem\n",
    "# 修改/root/cym/data01/utils/functions.py\n",
    "# number of GPU per node, number of nodes\n",
    "import numpy as np\n",
    "\n",
    "M = 4\n",
    "N = 4\n",
    "# home_path = \"/home/oj/distributed_floder/research/AMP\" #os.environ['HOME']\n",
    "home_path = \"/root/cym/AMP\"\n",
    "dir_path = os.path.join(home_path, 'amp_main_logs')\n",
    "if not os.path.exists(dir_path):\n",
    "    os.mkdir(dir_path)\n",
    "\n",
    "cluster_info = {}\n",
    "\n",
    "# # inter-node bandwidth, intra-node bandwidth\n",
    "# for i in range(N-1):\n",
    "#         cluster_info[i] = [mindspore.nmp([10 * 1e9 / 32]).float(), torch.tensor([170 * 1e9 / 32]).float()]\n",
    "# cluster_info[N-1] = [torch.tensor([50 * 1e9 / 32]).float(), torch.tensor([50 * 1e9 / 32]).float()]\n",
    "\n",
    "# model_config = {\"hidden_size\": torch.tensor([1024]).float(), \n",
    "#                 \"sequence_length\": torch.tensor([1024]).float(), \n",
    "#                 \"num_layers\": torch.tensor([24]).float(), \n",
    "#                 \"vocab_size\":torch.tensor([52256]).float(),\n",
    "#                 \"type\":\"gpt2\"}\n",
    "\n",
    "\n",
    "cluster_info = {}\n",
    "\n",
    "for i in range(N - 1):\n",
    "    cluster_info[i] = [mnp.array([10 * 1e9 / 32]).astype(mnp.float32), mnp.array([170 * 1e9 / 32]).astype(mnp.float32)]\n",
    "cluster_info[N - 1] = [mnp.array([50 * 1e9 / 32]).astype(mnp.float32), mnp.array([50 * 1e9 / 32]).astype(mnp.float32)]\n",
    "\n",
    "model_config = {\n",
    "    \"hidden_size\": mnp.array([1024]).astype(mnp.float32),\n",
    "    \"sequence_length\": mnp.array([1024]).astype(mnp.float32),\n",
    "    \"num_layers\": mnp.array([24]).astype(mnp.float32),\n",
    "    \"vocab_size\": mnp.array([52256]).astype(mnp.float32),\n",
    "    \"type\": \"gpt2\"\n",
    "}\n",
    "\n",
    "\n",
    "config_h = int((model_config[\"hidden_size\"]).item())\n",
    "config_n = int(model_config[\"num_layers\"].item())\n",
    "time_stamp = int(time.time())\n",
    "exp_name = f\"het_cluster\"\n",
    "record_file = f\"{os.path.join(dir_path, exp_name)}_{time_stamp}.txt\"\n",
    "simulate_dir = os.path.join(home_path, \"amp_simulate\")\n",
    "if not os.path.exists(simulate_dir):\n",
    "    os.mkdir(simulate_dir)\n",
    "print(\"record file : \", record_file)\n",
    "print(\"simulate dir : \", simulate_dir)\n",
    "\n",
    "# remove cache directory from last run\n",
    "if os.path.exists(os.path.join(home_path, \"tmp\")):\n",
    "    for root, dirs, files in os.walk(os.path.join(home_path, \"tmp\")):\n",
    "        for f in files:\n",
    "            os.unlink(os.path.join(root, f))\n",
    "\n",
    "# save this name to env\n",
    "os.environ[\"amp_log_path\"] = record_file\n",
    "def load_all_model():\n",
    "    models={}\n",
    "    # models[2], _ = load_model(\"./outputs/pp_30/pp30_2_rollout_20230402T234551/epoch-163.pt\")\n",
    "    # models[4],_ =  load_model(\"./outputs/pp_30/pp30_4_rollout_20230327T000146/epoch-99.pt\")\n",
    "    # models[8],_ = load_model(\"./outputs/pp_30/pp30_8_rollout_20230402T234340/epoch-134.pt\")\n",
    "    # models[16],_=  load_model(\"./outputs/pp_30/pp30_16_rollout_20230402T234155/epoch-62.pt\")\n",
    "    # models[2] = models[2].eval()\n",
    "    # models[2] = models[2].cuda()\n",
    "    # models[4] = models[4].eval()\n",
    "    # models[4] = models[4].cuda()\n",
    "    # models[8] = models[8].eval()\n",
    "    # models[8] = models[8].cuda()\n",
    "    # models[16] = models[16].eval()\n",
    "    # models[16] = models[16].cuda()\n",
    "    models[2], _ = load_model_temp(\"./outputs1/pp_8/pp_8_4_20231017T154608/epoch-14.ckpt\",1)\n",
    "    models[4],_ =  load_model_temp(\"./outputs1/pp_8/pp_8_4_20231017T154608/epoch-14.ckpt\",3)\n",
    "    models[8],_ = load_model_temp(\"./outputs1/pp_8/pp_8_4_20231017T154608/epoch-14.ckpt\",7)\n",
    "    models[16],_=  load_model_temp(\"./outputs1/pp_8/pp_8_4_20231017T154608/epoch-14.ckpt\",15)\n",
    "    models[2] = models[2].set_train(False)\n",
    "    models[4] = models[4].set_train(False)\n",
    "    models[8] = models[8].set_train(False)\n",
    "    models[16] = models[16].set_train(False)\n",
    "    return models\n",
    "\n",
    "load_all_model()\n",
    "def pi2partition(pi,node_size):\n",
    "    pi.sort()\n",
    "    # print(pi)\n",
    "    assert node_size > pi[-1]+1, print(node_size,pi)\n",
    "    piadd1 = [i+1 for i in pi]\n",
    "    piadd1 = [0] + piadd1 + [node_size]\n",
    "    partition = []\n",
    "    for i, p in enumerate(piadd1):\n",
    "        if i ==0:\n",
    "            continue\n",
    "        partition.append(p - piadd1[i-1])\n",
    "    return partition\n",
    "def get_partiton_cost_sequence(data,cost_c_data,partition):\n",
    "    # data = torch.Tensor(data)\n",
    "    pp=len(partition)\n",
    "    s = partition\n",
    "    p = [s[0]-1]\n",
    "\n",
    "\n",
    "    for i in range(1, pp):\n",
    "        p.append(p[i - 1] + s[i])\n",
    "    lens = ops.reshape(ops.sum(data[:p[0] + 1]), (-1, 1))\n",
    "\n",
    "    for i in range(len(s) - 1):\n",
    "        lens = ops.Concat((lens, ops.reshape(ops.sum(data[p[i] + 1:p[i + 1] + 1]), (-1, 1))), axis=0)\n",
    "\n",
    "    max_sub_seq_cost = lens.view(-1,).max()\n",
    "    for i in range(pp-1):\n",
    "        max_sub_seq_cost += cost_c_data[p[i]][i]\n",
    "    return max_sub_seq_cost\n",
    "# partition, _ = pipe_ast(len(cost_e), np.asarray(cost_e), np.asarray(cost_c), int(pp.item()), int(B.item()))\n",
    "def pipe_rl(models, L, cost_e, cost_c, k, B):\n",
    "    if k==1:\n",
    "        # return [cost_e.size(0)], None\n",
    "        return [cost_e.shape[0]], None\n",
    "    # print(cost_e.size(),cost_e)\n",
    "    # print(cost_c.size(),cost_c)\n",
    "    # ori_data = cost_e.view(1,-1,1).cuda()\n",
    "    ori_data = cost_e.view(1,-1,1)\n",
    "    # cost_c_data = cost_c[None,...].cuda()\n",
    "    cost_c_data = cost_c[None,...]\n",
    "    max_c = cost_c.max()\n",
    "    count_c = 0\n",
    "    while max_c <1:\n",
    "        count_c+=1\n",
    "        max_c = max_c * 10\n",
    "    max_e = cost_e.max()\n",
    "    count_e = 0\n",
    "    while max_e <1:\n",
    "        count_e+=1\n",
    "        max_e = max_e * 10\n",
    "    print(\"count_e: \",count_e )\n",
    "    print(\"count_c: \",count_c )\n",
    "    \n",
    "    time1=time.time()\n",
    "    new_data = []\n",
    "    new_sample = []\n",
    "    # n_cost_e = pow(10,count_e-1) * cost_e\n",
    "    # n_cost_c = pow(10,count_c-1) * cost_c\n",
    "    n_cost_e = cost_e/cost_e.max()#pow(10,count_e-1) * cost_e\n",
    "    n_cost_c = cost_c/cost_c.max()#pow(10,count_c-1) * cost_c\n",
    "    print(n_cost_e)\n",
    "    print(n_cost_c)\n",
    "    # for j in range(cost_e.size(0)-1):\n",
    "    for j in range(cost_e.shape[0]-1):\n",
    "        new_sample.append([sum(n_cost_e[:j+1]),sum(n_cost_e[j+1:])]+n_cost_c[j,:].tolist())\n",
    "    new_data.append(new_sample)\n",
    "    \n",
    "    # input_data =  torch.FloatTensor(new_data).cuda()\n",
    "    context.set_context(device_target=\"GPU\")\n",
    "    input_data = mnp.array(new_data).astype(mnp.float32)\n",
    "\n",
    "    model = models[k]\n",
    "    set_decode_type(model, \"greedy\")\n",
    "    \n",
    "    cost, log_likelihood, pi = model(input_data, ori_data, cost_c_data, return_pi=True)\n",
    "    # print(pi)\n",
    "    # part = pi2partition(pi[0].tolist(),cost_e.size(0))\n",
    "    part = pi2partition(pi[0].tolist(),cost_e.shape[0])\n",
    "    time2= time.time()\n",
    "    print(\"GNN cost: \", time2-time1, \"cost: \", cost)\n",
    "    return part, None\n",
    "    # gnn_cots = get_partiton_cost_sequence(ori_data.view(-1),cost_c_data[0,...],part)\n",
    "# home_dir = \"/home/oj/distributed_floder/research/AMP\" #os.environ['HOME']\n",
    "home_dir = \"/root/cym/AMP\" #os.environ['HOME']\n",
    "\n",
    "workdir_path = os.path.join(home_dir, \"AMP/DeepSpeed/DeepSpeedExamples/Megatron-LM-v1.1.5-3D_parallelism\")\n",
    "example_path = os.path.join(workdir_path, \"examples\")\n",
    "sys.path.append(workdir_path)\n",
    "sys.path.append(example_path)\n",
    "\n",
    "class AMP(nn.Cell):\n",
    "    def __init__(self, model_config, exp_name, placement=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.model_config = model_config\n",
    "        #self.estimate = estimate\n",
    "        self.model_type = model_config[\"type\"]\n",
    "        self.placement = placement\n",
    "        assert self.model_type == \"gpt2\" \n",
    "        self.init_param()\n",
    "        \n",
    "    def init_param(self):\n",
    "        h = float(self.model_config[\"hidden_size\"].item())\n",
    "        n = float(self.model_config[\"num_layers\"].item())\n",
    "        s = float(self.model_config[\"sequence_length\"].item())\n",
    "        v = float(self.model_config[\"vocab_size\"].item())\n",
    " \n",
    "        config_h = int((self.model_config[\"hidden_size\"]).item())\n",
    "        config_n = int(n)\n",
    "\n",
    "        json_path = os.path.join(example_path, \"ds_config.json\")\n",
    "        self.profile_cost = {}\n",
    "        #if self.estimate:\n",
    "        for mp_size in [1,2,4]:\n",
    "            # known_cost directory stores the real forward time with correponding model parallel degree.\n",
    "            \n",
    "            # known_record = f\"/home/oj/distributed_floder/research/AMP/src/known_cost/{self.model_type}_P3_{mp_size}\"\n",
    "            known_record = f\"/root/cym/AMP/src/known_cost/{self.model_type}_P3_{mp_size}\"\n",
    "            \n",
    "            cur_profile_cost1 = 3 * np.load(f\"{known_record}.npy\")\n",
    "            \n",
    "            # known_record = f\"/home/oj/distributed_floder/research/AMP/src/known_cost/{self.model_type}_G4_{mp_size}\"\n",
    "            known_record = f\"/root/cym/AMP/src/known_cost/{self.model_type}_P3_{mp_size}\"\n",
    "            cur_profile_cost2 = 3 * np.load(f\"{known_record}.npy\")\n",
    "\n",
    "            # average between different speed of GPUs\n",
    "            cur_profile_cost = cur_profile_cost1 * 0.75 + cur_profile_cost2 * 0.25\n",
    "            self.profile_cost[str(mp_size)] = cur_profile_cost\n",
    "            #print(f\"using profile cost with mp_size {mp_size}: {cur_profile_cost}\")\n",
    "       \n",
    "        self.models = load_all_model()\n",
    "            \n",
    "    def predict(self, config, bs, mbs, cluster_info, model_config, amp_config, oth):\n",
    "        L = model_config[\"num_layers\"]\n",
    "        \n",
    "        # cost = torch.zeros(1,)\n",
    "        cost = mnp.zeros((1,))\n",
    "        \n",
    "        M, N = config.shape\n",
    "        config = np.asarray(config)\n",
    "\n",
    "        if np.all(config == -1):\n",
    "            rank_map = defaultdict(list)\n",
    "            rank_node_map = dict()\n",
    "\n",
    "            m = oth[\"mp_deg\"]\n",
    "            n = oth[\"dp_deg\"]\n",
    "            pp = oth[\"pp_deg\"]                   \n",
    "\n",
    "            # infer a GPU rank map                \n",
    "            counter = 0    \n",
    "            for j in range(N):\n",
    "                for k in range(M):\n",
    "                    # TODO: bad code here, config counts from 1\n",
    "                    rank_map[j].append(counter)\n",
    "                    rank_node_map[counter] = j\n",
    "                    counter += 1\n",
    "\n",
    "            #print(f\"AMP estimate default to {rank_map}\")\n",
    "\n",
    "        # valid config, inferred from sa \n",
    "        else:\n",
    "            config = torch.from_numpy(config)\n",
    "            pp = torch.max(config).float()\n",
    "\n",
    "            # infer rank_map: given node name, returns the global mapped rank(int) in (pp, dp, mp) order\n",
    "            # rank_node_map: given rank, returns the node\n",
    "            rank_map = defaultdict(list)\n",
    "            rank_node_map = dict()\n",
    "\n",
    "            if pp >= (L + 2):\n",
    "                print(f\"early return with pp={pp}, L={L}\")\n",
    "                return None, None, torch.tensor([float(\"inf\")])\n",
    "\n",
    "            m = oth[\"mp_deg\"]\n",
    "            n = oth[\"dp_deg\"]\n",
    "            assert pp == oth[\"pp_deg\"]                   \n",
    "\n",
    "            rank_counter = np.zeros(int(pp.item()))\n",
    "\n",
    "            # infer a GPU rank map                    \n",
    "            for j in range(N):\n",
    "                for k in range(M):\n",
    "                    # TODO: bad code here, config counts from 1\n",
    "                    cur_pp = int(config[k][j] - 1)\n",
    "                    rank_map[j].append(int((rank_counter[cur_pp] + cur_pp * m * n).item()))\n",
    "                    rank_node_map[int((rank_counter[cur_pp] + cur_pp * m * n).item())] = j\n",
    "                    rank_counter[cur_pp] += 1\n",
    "\n",
    "        # infer number of micro-batch size B\n",
    "        B = bs / (n * mbs)\n",
    "\n",
    "        parallel_config = {\"mp\" : m, \"dp\" : n, \"pp\" : pp, \"micro_bs\" : mbs, \"rank_map\" : rank_map, \"rank_node_map\": rank_node_map}\n",
    "\n",
    "        cost_e = get_cost_e(cluster_info=cluster_info, \n",
    "                            model_config=model_config, parallel_config=parallel_config, amp_config=amp_config)\n",
    "        cost_c = get_cost_c(cluster_info=cluster_info, \n",
    "                            model_config=model_config, parallel_config=parallel_config, amp_config=amp_config)\n",
    "\n",
    "        #partition, _ = pipe_dp(int(L.item()), np.asarray(cost_e.detach()), np.asarray(cost_c.detach()), int(pp.item()), int(B.item()))\n",
    "        if int(B.item()) == 1:\n",
    "            partition, _ = pipe_uniform(int(L.item()), int(pp.item()))\n",
    "            partition[0] += 2\n",
    "            partition[-1] += 4\n",
    "        else:\n",
    "            # partition, _ = pipe_ast(len(cost_e), np.asarray(cost_e), np.asarray(cost_c), int(pp.item()), int(B.item()))\n",
    "            # partition, _ = pipe_rl_sample(self.models, len(cost_e), cost_e, cost_c, int(pp.item()), int(B.item()))\n",
    "            partition, _ = pipe_rl(self.models, len(cost_e), cost_e, cost_c, int(pp.item()), int(B.item()))\n",
    "            \n",
    "        print(f\"amp gives partition: {partition}\")\n",
    "        cost = pipe_cost(L, cost_e, cost_c, pp, B, partition)\n",
    "\n",
    "        # translate to ds form, add data parallelism cost\n",
    "        ds_partition, dp_side_cost = dp_cost(config, cluster_info=cluster_info, \n",
    "                            model_config=model_config, parallel_config=parallel_config, \n",
    "                            amp_config=amp_config, partition=partition)\n",
    "\n",
    "        cost += dp_side_cost\n",
    "        #print(ds_partition, cost, dp_side_cost)\n",
    "        return rank_map, ds_partition, cost\n",
    "\n",
    "   \n",
    "    def construct(self, args):\n",
    "        model_type = self.model_type\n",
    "        config, bs, micro_bs, cluster_info, model_config, oth = args\n",
    "        amp_config = {\"profile_cost\" : self.profile_cost}\n",
    "        rank_map, partition, amp_pred = self.predict(config, bs, micro_bs, cluster_info, model_config, amp_config, oth)\n",
    "        return rank_map, partition, amp_pred\n",
    "global_bs = 32\n",
    "model = AMP(model_config, exp_name)\n",
    "assert (global_bs % M == 0) and (global_bs % N == 0), \"global batch size is too irrgular\"\n",
    "\n",
    "want_simulate = [] \n",
    "feasible = {}\n",
    "\n",
    "with open(record_file, \"a\") as fp:\n",
    "    fp.write(f\"{model_config}\\n\")                \n",
    "    fp.write(f\"gbs:{global_bs}\\n\")                \n",
    "known = None\n",
    "iter_count = 0\n",
    "known=None\n",
    "time_s = time.time()\n",
    "# Estimating best configurations\n",
    "while True:\n",
    "    ret = amp_no_placement_strategy(M=M, N=N, gbs=global_bs, known=known)\n",
    "    if ret is None:\n",
    "        break\n",
    "    else:\n",
    "        mp, dp, mbs, known = ret\n",
    "        # oth = {\"mp_deg\": torch.ones(1,)*mp, \"dp_deg\": torch.ones(1,)*dp, \"pp_deg\": torch.ones(1,)*(M*N/(mp*dp))}\n",
    "        oth = {\"mp_deg\": ops.ones(1,mindspore.float32)*mp, \"dp_deg\": ops.ones(1,mindspore.float32)*dp, \"pp_deg\": ops.ones(1,mindspore.float32)*(M*N/(mp*dp))}\n",
    "        fake_config = np.ones((M,N)) * (-1)\n",
    "        model_args = (fake_config, global_bs, mbs, cluster_info, model_config, oth)    \n",
    "        if (M*N)/(mp*dp)>30:\n",
    "            continue\n",
    "        # with torch.no_grad():\n",
    "        rank_map, partition, cost = model(model_args)\n",
    "        \n",
    "        want_simulate.append(((mbs, oth, rank_map, partition), cost))\n",
    "    iter_count += 1\n",
    "    if iter_count % 10 == 0:\n",
    "        print(f\"AMP finish {iter_count} iterations\")\n",
    "time_e = time.time()\n",
    "print(f\"AMP finishes without placement in {iter_count} iterations in {time_e - time_s}\")\n",
    "\n",
    "sorted_settings = sorted(want_simulate, key = lambda kv: kv[1])\n",
    "print(record_file)\n",
    "with open(record_file, \"a\") as fp:\n",
    "    for item in sorted_settings:\n",
    "        fp.write(f\"rank {sorted_settings.index(item)}: {item}\")\n",
    "        fp.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
